apiVersion: apps/v1
kind: Deployment
metadata:
  name: local-ai-deployment
  namespace: k8sgpt-operator-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: local-ai
  template:
    metadata:
      labels:
        app: local-ai
    spec:
      initContainers:
      - name: download-models
        image: busybox
        command:
        - /bin/sh
        - -c
        - |
          wget -P /models https://gpt4all.io/models/ggml-gpt4all-j.bin
          # Add more wget commands if you have more models to download
        volumeMounts:
        - mountPath: /models
          name: model-volume
      containers:
      - name: local-ai
        image: quay.io/go-skynet/local-ai:master-ffmpeg-core
        env:
        - name: THREADS
          value: "4"
        - name: CONTEXT_SIZE
          value: "512"
        - name: MODELS_PATH
          value: "/models"
        - name: PRELOAD_MODELS
          value: '["/models/ggml-gpt4all-j.bin"]'  # Ensure the path and name match the downloaded model
        volumeMounts:
        - mountPath: /models
          name: model-volume
        resources:
          requests:
            ephemeral-storage: "10Gi"
      volumes:
      - name: model-volume
        persistentVolumeClaim:
          claimName: model-pvc
